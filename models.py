import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from util import add_inverse_rels
from torch_sparse import spmm
from torch_geometric.utils import softmax, degree


class GCN(nn.Module):
    def __init__(self, hidden):
        super(GCN, self).__init__()

    def forward(self, x, edge_index):
        edge_index_j, edge_index_i = edge_index
        deg = degree(edge_index_i, x.size(0), dtype=x.dtype)  # degree of each entity in KG
        deg_inv_sqrt = deg.pow(-0.5)
        norm = deg_inv_sqrt[edge_index_j] * deg_inv_sqrt[edge_index_i]
        x = F.relu(spmm(edge_index[[1, 0]], norm, x.size(0), x.size(0), x))  # edge_index[[1, 0]] represents the index of the values in the KG sparse matrix, corresponding to the values in the norm, and x is the dense matrix of the entity embedding
        return x

class Highway(nn.Module):
    def __init__(self, x_hidden):
        super(Highway, self).__init__()
        self.lin = nn.Linear(x_hidden, x_hidden)

    def forward(self, x1, x2):
        # print(self.lin.in_features, self.lin.out_features, self.lin.weight.shape, self.lin.bias.shape,'____', x1.shape)
        a = self.lin(x1)
        # print(a.shape)
        gate = torch.sigmoid(a)
        x = torch.mul(gate, x2) + torch.mul(1 - gate, x1)
        return x


class GAT_E_to_R(nn.Module):  # The relation representation is generated by the entity embedding
    def __init__(self, e_hidden, r_hidden):
        super(GAT_E_to_R, self).__init__()
        self.a_h1 = nn.Linear(r_hidden, 1, bias=False)
        self.a_h2 = nn.Linear(r_hidden, 1, bias=False)
        self.a_t1 = nn.Linear(r_hidden, 1, bias=False)
        self.a_t2 = nn.Linear(r_hidden, 1, bias=False)
        self.w_h = nn.Linear(e_hidden, r_hidden, bias=False)
        self.w_t = nn.Linear(e_hidden, r_hidden, bias=False)

    def forward(self, x_e, edge_index, rel):
        edge_index_h, edge_index_t = edge_index
        x_r_h = self.w_h(x_e)
        x_r_t = self.w_t(x_e)

        e1 = self.a_h1(x_r_h).squeeze()[edge_index_h] + self.a_h2(x_r_t).squeeze()[edge_index_t]
        e2 = self.a_t1(x_r_h).squeeze()[edge_index_h] + self.a_t2(x_r_t).squeeze()[edge_index_t]

        alpha = softmax(F.leaky_relu(e1).float(), rel)
        x_r_h = spmm(torch.cat([rel.view(1, -1), edge_index_h.view(1, -1)], dim=0), alpha, rel.max() + 1, x_e.size(0), x_r_h)

        alpha = softmax(F.leaky_relu(e2).float(), rel)
        x_r_t = spmm(torch.cat([rel.view(1, -1), edge_index_t.view(1, -1)], dim=0), alpha, rel.max() + 1, x_e.size(0), x_r_t)
        x_r = x_r_h + x_r_t
        return x_r


class GAT_R_to_E(nn.Module):
    def __init__(self, e_hidden, r_hidden):
        super(GAT_R_to_E, self).__init__()
        self.a_h = nn.Linear(e_hidden, 1, bias=False)
        self.a_t = nn.Linear(e_hidden, 1, bias=False)
        self.a_r = nn.Linear(r_hidden, 1, bias=False)

    def forward(self, x_e, x_r, edge_index, rel):
        edge_index_h, edge_index_t = edge_index
        e_h = self.a_h(x_e).squeeze()[edge_index_h]
        e_t = self.a_t(x_e).squeeze()[edge_index_t]
        e_r = self.a_r(x_r).squeeze()[rel]
        alpha = softmax(F.leaky_relu(e_h + e_r).float(), edge_index_h)
        x_e_h = spmm(torch.cat([edge_index_h.view(1, -1), rel.view(1, -1)], dim=0), alpha, x_e.size(0), x_r.size(0), x_r)  # out-relation embedding of an entity. The dimension of each entity is r-hidden
        alpha = softmax(F.leaky_relu(e_t + e_r).float(), edge_index_t)
        x_e_t = spmm(torch.cat([edge_index_t.view(1, -1), rel.view(1, -1)], dim=0), alpha, x_e.size(0), x_r.size(0), x_r)  # in-relation embedding of an entity. The dimension of each entity is r-hidden
        x = torch.cat([x_e_h, x_e_t], dim=1)
        return x


class GAT(nn.Module):
    def __init__(self, hidden):
        super(GAT, self).__init__()
        self.a_i = nn.Linear(hidden, 1, bias=False)
        self.a_j = nn.Linear(hidden, 1, bias=False)
        self.a_r = nn.Linear(hidden, 1, bias=False)

    def forward(self, x, edge_index):
        edge_index_j, edge_index_i = edge_index
        e_i = self.a_i(x).squeeze()[edge_index_i]
        e_j = self.a_j(x).squeeze()[edge_index_j]
        e = e_i + e_j
        alpha = softmax(F.leaky_relu(e).float(), edge_index_i)
        x = F.relu(spmm(edge_index[[1, 0]], alpha, x.size(0), x.size(0), x))
        return x

# """
class RAGA(nn.Module):  # with RGAT
    def __init__(self, e_hidden=128, r_hidden=64):
        super(RAGA, self).__init__()
        self.gcn1 = GCN(e_hidden)
        self.highway1 = Highway(e_hidden)
        self.gcn2 = GCN(e_hidden)
        self.highway2 = Highway(e_hidden)
        self.gat_e_to_r = GAT_E_to_R(e_hidden, r_hidden)
        self.gat_r_to_e = GAT_R_to_E(e_hidden, r_hidden)
        self.gat = GAT(e_hidden+2*r_hidden)

    def forward(self, x_e, edge_index, rel, edge_index_all):
        x_e = self.highway1(x_e, self.gcn1(x_e, edge_index_all))
        x_e = self.highway2(x_e, self.gcn2(x_e, edge_index_all))
        x_r = self.gat_e_to_r(x_e, edge_index, rel)
        x_e = torch.cat([x_e, self.gat_r_to_e(x_e, x_r, edge_index, rel)], dim=1)
        x_e = torch.cat([x_e, self.gat(x_e, edge_index_all)], dim=1)
        return x_e
# """

"""
class RAGA(nn.Module):  # without RGAT
    def __init__(self, e_hidden=128, r_hidden=64):  # By default, the ent emb of RAGA input is 128 dimensional, and the rel emb output is 64 dimensional
        super(RAGA, self).__init__()
        self.gcn1 = GCN(e_hidden)
        self.highway1 = Highway(e_hidden)
        self.gcn2 = GCN(e_hidden)
        self.highway2 = Highway(e_hidden)
        self.gat_e_to_r = GAT_E_to_R(e_hidden, r_hidden)
        self.gat_r_to_e = GAT_R_to_E(e_hidden, r_hidden)
        self.gat = GAT(e_hidden+2*r_hidden)

    def forward(self, x_e, edge_index, rel, edge_index_all, rel_all):
        # Deep of Highway-GCN is 2 layers
        x_e = self.highway1(x_e, self.gcn1(x_e, edge_index_all))
        x_e = self.highway2(x_e, self.gcn2(x_e, edge_index_all))
        return x_e
"""


class GraphConvolution(nn.Module):
    def __init__(self, input_dim, output_dim, featureless=False, act_func=F.relu, residual=True):
        super(GraphConvolution, self).__init__()
        self.act_func = act_func
        self.residual = residual
        self.featureless = featureless
        if self.residual and input_dim != output_dim:
            self.root = nn.Linear(input_dim, output_dim, False)
            nn.init.xavier_uniform_(self.root.weight)
        if not self.featureless:
            self.linear = nn.Linear(input_dim, output_dim)
            nn.init.xavier_uniform_(self.linear.weight)

    def forward(self, adj, feats):
        to_feats = torch.sparse.mm(adj, feats)
        degree = torch.sparse.sum(adj, dim=1).to_dense().reshape(-1, 1)
        to_feats = to_feats / degree
        if not self.featureless:
            to_feats = self.linear(to_feats)
        to_feats = self.act_func(to_feats)
        if self.residual:
            if feats.shape[-1] != to_feats.shape[-1]:
                to_feats = self.root(feats) + to_feats
            else:
                to_feats = feats + to_feats
        return to_feats


class MultiLayerGCN(nn.Module):
    def __init__(self, in_dim, out_dim, num_layer, dropout_rate=0.5, featureless=True, residual=False):
        super(MultiLayerGCN, self).__init__()
        self.residual = residual
        self.dropout = nn.Dropout(dropout_rate)
        self.gcn_list = nn.ModuleList()
        assert num_layer >= 1
        dim = in_dim
        for i in range(num_layer - 1):
            if i == 0:
                self.gcn_list.append(GraphConvolution(dim, out_dim, featureless, residual=residual))
                dim = out_dim
            else:
                self.gcn_list.append(GraphConvolution(out_dim, out_dim, False, residual=residual))
        self.gcn_list.append(GraphConvolution(dim, out_dim, False, act_func=lambda x: x, residual=residual))

    def preprocess_adj(self, edges):
        device = next(self.parameters()).device
        edges = torch.cat((edges, edges.flip(dims=[1, ])), dim=0)
        adj = torch.sparse.FloatTensor(edges.transpose(0, 1), torch.ones(edges.shape[0], device=device))
        M, N = adj.shape
        assert M == N
        if not self.residual:
            self_loop = torch.arange(N, device=device).reshape(-1, 1).repeat(1, 2)
            self_loop = torch.sparse.FloatTensor(self_loop.transpose(0, 1),
                                                 torch.ones(self_loop.shape[0], device=device))
            adj = adj + self_loop
        adj = adj.coalesce()
        torch.clamp_max_(adj._values(), 1)
        return adj

    def forward(self, edges, graph_embedding):
        adj = self.preprocess_adj(edges)
        for gcn in self.gcn_list:
            graph_embedding = self.dropout(graph_embedding)
            graph_embedding = gcn(adj, graph_embedding)
        return graph_embedding


class AttributedEncoder(nn.Module):
    def __init__(self, key_dim, val_dim):
        super(AttributedEncoder, self).__init__()
        self.a = nn.Linear(key_dim * 2, 1)
        nn.init.xavier_uniform_(self.a.weight)
        self.W = nn.Parameter(torch.zeros(key_dim + val_dim, key_dim))
        nn.init.xavier_uniform_(self.W)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)

    def forward(self, attribute_triples, att_feats, val_feats, ent_feats): # Use the attention mechanism to aggregate attributes for each entity, returning the aggregated entity embedding
        ## fixme: consider not use norisy attribute if all the attribute are noisy
        ## fixme: consider share the attribute importance to all nodes
        N = ent_feats.shape[0]  # Number of entities in a graph
        E = attribute_triples.shape[0]  # The number of attribute triple values in a graph
        device = ent_feats.device
        h, val, att = attribute_triples.transpose(0, 1)  # shape=[E]

        attention_score = self.a(torch.cat((ent_feats[h], att_feats[att]), dim=-1))
        attention_score = attention_score.squeeze(-1)  # shape = [E,]
        attention_score = torch.exp(self.leaky_relu(attention_score))
        edges = torch.stack((h, torch.arange(E, device=device)), dim=0)
        incidence_matrix = torch.sparse.FloatTensor(edges, torch.ones(edges.shape[1], device=device), size=(N, E))  # shape = [N, E]
        row_sum = torch.sparse.mm(incidence_matrix, attention_score.reshape(-1, 1)).squeeze(-1)  # shape = [N,]
        attention_p = attention_score / row_sum[h]  # shape = [E]
        att_vals = torch.cat((att_feats[att], val_feats[val]), dim=1)  # shape [E, dim1 + dim2]
        att_vals = att_vals @ self.W  # shape = [E, dim]
        # att_vals = self.W(att_vals)

        att_vals = att_vals * attention_p.reshape(-1, 1)  # shape = [E, dim]
        to_feats = torch.sparse.mm(incidence_matrix, att_vals)  # shape = [N, dim]
        to_feats = to_feats + ent_feats
        to_feats = F.elu(to_feats)
        return to_feats


class AttSeq(nn.Module):
    def __init__(self, layer_num, sr_ent_num, tg_ent_num, dim, drop_out, att_num, attribute_triples_sr, attribute_triples_tg, value_embedding, edges_sr, edges_tg, residual=True):
        super(AttSeq, self).__init__()
        self.residual = residual
        ## KG Feature Loading
        self.edges_index_sr = edges_sr.t()
        self.edges_index_tg = edges_tg.t()
        self.attribute_triples_sr = nn.Parameter(attribute_triples_sr, requires_grad=False)  # shape = [E1, 3]
        self.attribute_triples_tg = nn.Parameter(attribute_triples_tg, requires_grad=False)  # shape = [E2, 3]
        self.val_feats = nn.Parameter(torch.from_numpy(value_embedding), requires_grad=False)

        att_num += 1  # + 1 for unrecognized attribute
        ## Initialize trainable embeddings
        embedding_weight = torch.zeros((att_num + sr_ent_num + tg_ent_num, dim), dtype=torch.float, requires_grad=False)
        nn.init.xavier_uniform_(embedding_weight)
        self.att_feats = nn.Parameter(embedding_weight[:att_num], requires_grad=True)
        self.ent_feats_sr = nn.Parameter(embedding_weight[att_num: att_num + sr_ent_num], requires_grad=True)
        self.ent_feats_tg = nn.Parameter(embedding_weight[att_num + sr_ent_num:], requires_grad=True)

        ## initialize networks
        self.value_encoder = AttributedEncoder(dim, value_embedding.shape[1])
        self.gnns = nn.ModuleList()
        assert layer_num >= 1
        layer_num -= 1
        for i in range(layer_num):
            if i == layer_num - 1:
                self.gnns.append(GraphConvolution(dim, dim, featureless=False, residual=residual, act_func=lambda x: x))
            else:
                self.gnns.append(GraphConvolution(dim, dim, featureless=False, residual=residual))

    def preprocess_adj(self, edges): # Input all edges of the graph and return the adjacency matrix representing the graph
        device = next(self.parameters()).device
        edges = torch.cat((edges, edges.flip(dims=[1, ])), dim=0)  # shape=[E * 2, 2] Flip each edge and merge it with the original edge to get a bidirectional relationship
        adj = torch.sparse.FloatTensor(edges.transpose(0, 1), torch.ones(edges.shape[0], device=device))
        M, N = adj.shape
        assert M == N

        self_loop = torch.arange(N, device=device).reshape(-1, 1).repeat(1, 2)  # shape = [N, 2]   Each node also has a relationship with itself, so that the diagonal elements of the adjacency matrix representing the graph are all ones
        self_loop = torch.sparse.FloatTensor(self_loop.transpose(0, 1), torch.ones(self_loop.shape[0], device=device))
        adj = adj + self_loop

        adj = adj.coalesce()  # Sum multiple values of the same index
        torch.clamp_max_(adj._values(), 1)
        return adj

    def forward(self, ent_seed_sr, ent_seed_tg, triples_sr, triples_tg):
        device = next(self.parameters()).device
        ent_feats_sr = self.value_encoder(self.attribute_triples_sr, self.att_feats, self.val_feats, self.ent_feats_sr)
        ent_feats_tg = self.value_encoder(self.attribute_triples_tg, self.att_feats, self.val_feats, self.ent_feats_tg)
        rel_sr = torch.from_numpy(np.array([i[2] for i in triples_sr])).to(device)
        rel_tg = torch.from_numpy(np.array([i[2] for i in triples_tg])).to(device)
        edges_index_sr = self.edges_index_sr.to(device)
        edges_index_tg = self.edges_index_tg.to(device)
        edges_index_all_sr, rel_all_sr = add_inverse_rels(edges_index_sr, rel_sr)
        edges_index_all_tg, rel_all_tg = add_inverse_rels(edges_index_tg, rel_tg)

        ent_emb_dim = ent_feats_sr.size(1)
        raga_model = RAGA(ent_emb_dim, int(ent_emb_dim/2)).to(device)

        ent_feats_sr = raga_model(ent_feats_sr, edges_index_sr, rel_sr, edges_index_all_sr)
        ent_feats_tg = raga_model(ent_feats_tg, edges_index_tg, rel_tg, edges_index_all_tg)

        ent_feats_sr = F.normalize(ent_feats_sr, p=2, dim=-1)
        ent_feats_tg = F.normalize(ent_feats_tg, p=2, dim=-1)
        sr_seed_feats = ent_feats_sr[ent_seed_sr]
        tg_seed_feats = ent_feats_tg[ent_seed_tg]
        return sr_seed_feats, tg_seed_feats, ent_feats_sr, ent_feats_tg